# -*- coding: utf-8 -*-
"""CNN_Autoencoder.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ao_EYgX0KRIQOcCjDJnDdPo2f8uZ4aub
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import torch
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import torchvision
import torchvision.transforms as transforms
from torch.autograd import Variable, Function
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import copy 
import time

transform = transforms.Compose([transforms.ToTensor])
BatchSize = 2000
trainset = torchvision.datasets.CIFAR10(root ='./CIFAR10', train = True, download = True, transform=True)
trainloader = torch.utils.data.DataLoader(trainset, batch_size= BatchSize, shuffle = True, num_workers = 4)# creating Dataloader

testset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=BatchSize,
                                         shuffle=False, num_workers=4) # Creating dataloader

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

use_gpu =  torch.cuda.is_available()
if use_gpu:
  print("GPU is available")
else:
  print("Not available")

# Convolution Autoencoder
class autoencoder(nn.Module):
  def __init__(self):
    super(autoencoder, self).__init__()
    self.conv_encoder = nn.Sequential(
        nn.Conv2d(in_channels= 3, out_channels= 64, kernel_size= 3 , stride = 2, padding =1), # 16*16,
        nn.LeakyReLU(0.1),
        nn.Conv2d(in_channels= 64, out_channels= 128, kernel_size= 3 , stride = 2, padding =1),# 8*8,
        nn.Conv2d(in_channels= 128, out_channels= 128, kernel_size= 3 , stride = 2, padding =1),#4*4,
        nn.LeakyReLU(0.1)
        )
    self.fc_encoder = nn.Sequential(
        nn.Linear(128*4*4, 1024),
        nn.LeakyReLU(0.1))
    self.fc_decoder = nn.Sequential(
        nn.Linear(1024, 128*4*4))
    self.conv_decoder = nn.Sequential(
        nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1, padding =1),
        nn.LeakyReLU(0.1),
        nn.Upsample(scale_factor=2, mode = 'bilinear'),# Interpolation, 8*8
        nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = 3, stride = 1, padding =1),
        nn.LeakyReLU(0.1),
        nn.Upsample(scale_factor=2, mode = 'bilinear'),# Interpolation, 16*16
        nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding =1),
        nn.LeakyReLU(0.1),
        nn.Upsample(scale_factor=2, mode = 'bilinear'),# Interpolation, 32*32
        nn.Conv2d(in_channels = 64, out_channels = 3, kernel_size = 3, stride = 1, padding =1),
        nn.ReLU())
    
    def forward(self, x):
      x = self.conv_encoder(x)
      x = x.view(-1, 128*4*4) # Linearize, single layer
      x = self.fc_encoder(x) # Feeding to the encoder
      x = self.fc_decoder(x) # Feeding to the deocder
      x = x.view(-1, 128,4,4) # tensor of 128*4*4
      x = self.conv_decoder(x)  # Convolutional decoder block
      return x

net = autoencoder()

print(net)
init_weights = copy.deepcopy(net.conv_encoder[0].weight.data)

# TRAINIG THE AUTO ENCODER
iterations = 5
criterion = nn.MSELoss() ## Regression type
optimizer = optim.Adam(net.parameters(), lr = 1e-3)
testacc = []
trainloss = []
for epoch in range(iterations):
  epochStart = time.time()
  runningLoss = 0.0
  for i, data in enumerate(trainloader, 0):
    #gets the inputs
    inputs, labels = data
    # wrap them in Variable
    if use_gpu:
      inputs = Variable(inputs).cuda()
    else:
      inputs = Variable(inputs)
  
    optimizer.zero_grad() # zeros the gradient buffers of all parameters
    outputs = net(inputs) # forward
    loss = criterion(outputs, inputs) # Calculate loss
    loss.backward() # backpropagate the loss

    optimizer.step()
    runningLoss += loss.data[0]

  trainLoss.append((runningLoss/(60000/BatchSize)))
  epochEnd = time.time()-epochStart
  print('Iteration: {:.0f}/{:.0f}; Training_LOSS: {:.6f},  Time Consumed = {:.0f}m {:.0f}s'\
          .format(epoch + 1,iterations,runningLoss/(60000/BatchSize),epochEnd//60,epochEnd%60))

print("FINISHED TRAINING")

plt.plot(range(epoch+1), trainloss, 'g-', label='Loss')
plt.legend(loc='best')
plt.xlabel('Epochs')
plt.ylabel('Training Loss')

### weight viisualisation
cll_weights_ft = copy.deepcopy(net.conv[0].weight.data)
d_weights = cll_weights-cll_weights_ft 

if use_gpu:
    cll_weights = cll_weights.view(64,3,3,3).cpu()
    cll_weights_ft = cll_weights_ft.view(64,3,3,3).cpu()
    d_weights = d_weights.view(64,3,3,3).cpu()
else:
    cll_weights = cll_weights.view((64,3,3,3))
    cll_weights_ft = cll_weights_ft.view((64,3,3,3))
    d_weights = d_weights.view((64,3,3,3))

imshow(torchvision.utils.make_grid(cll_weights,nrow=8,normalize=True),'Trained Weights')
imshow(torchvision.utils.make_grid(cll_weights_ft,nrow=8,normalize=True),'Finetuned Weights')
imshow(torchvision.utils.make_grid(d_weights,nrow=8,normalize=True), 'Weight update')

### Performance of different classes
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
for data in testloader:
    images, labels = data
    if use_gpu:
        outputs = net(Variable(images.cuda()))
        _, predicted = torch.max(outputs.data.cpu(), 1)
    else:
        outputs = net(Variable(images))
        _, predicted = torch.max(outputs.data, 1)
    c = (predicted == labels).squeeze()
    for i in range(BatchSize):
        label = labels[i]
        class_correct[label] += c[i]
        class_total[label] += 1

for i in range(10):
    print('Accuracy of %5s : %f %%' % (
        classes[i], 100 * class_correct[i] / float(class_total[i])))